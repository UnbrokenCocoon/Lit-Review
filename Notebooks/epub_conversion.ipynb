{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install epub-conversion\n",
        "from epub_conversion import Converter\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "director_path = 'path/to/your/directory'\n",
        "converter = Converter(directory_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D1PEzvumI5y",
        "outputId": "d95dbaca-f01d-4657-be04-5c5584d91c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting epub-conversion\n",
            "  Downloading epub-conversion-1.0.15.tar.gz (6.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bz2file (from epub-conversion)\n",
            "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting epub (from epub-conversion)\n",
            "  Downloading epub-0.5.2.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ciseau (from epub-conversion)\n",
            "  Downloading ciseau-1.0.1.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: epub-conversion, bz2file, ciseau, epub\n",
            "  Building wheel for epub-conversion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epub-conversion: filename=epub_conversion-1.0.15-py3-none-any.whl size=7370 sha256=2483ad24b47f1f92edc08b3909f137f66db1966c3eeadc0f209a30791c9fe57c\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/ce/7c/da2558555a0abaca49d6d6d71c2fd274420992ca9267fe40f3\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6868 sha256=c362fc3e79602e4bfde520bd584309dbbb57c0287a5e234ced3f1fb78d4a7f9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/dc/a2/d5648eee379349a57b03ccf386862f09826575087464f070b2\n",
            "  Building wheel for ciseau (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ciseau: filename=ciseau-1.0.1-py3-none-any.whl size=12234 sha256=4ced11c9ed0fcef39a174e496ff148b613179e66e467cf0b004c3c0e9b041d7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/76/64/843e2e2fb03ff1054838c2be803986012de84796a9b0a7e5ce\n",
            "  Building wheel for epub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epub: filename=epub-0.5.2-py3-none-any.whl size=16304 sha256=2c56e3aef34b07ef7d8b8e24a1bfe2b6de3904705203c559e0e3bdd9ffaa5590\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/fe/2f/42a96c315cc581a137c068cb3d1805a40ac1216411f911da91\n",
            "Successfully built epub-conversion bz2file ciseau epub\n",
            "Installing collected packages: epub, ciseau, bz2file, epub-conversion\n",
            "Successfully installed bz2file-0.98 ciseau-1.0.1 epub-0.5.2 epub-conversion-1.0.15\n",
            "Collecting xml_cleaner\n",
            "  Downloading xml-cleaner-2.0.4.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xml_cleaner\n",
            "  Building wheel for xml_cleaner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xml_cleaner: filename=xml_cleaner-2.0.4-py3-none-any.whl size=12141 sha256=b3e9272839f56aba01416a34938eed006f2c14650f6b434cb5bdf4cf40792d2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8a/98/a7f76dc49e99f062816024b3bd07b4bbe064a117770f2daf8e\n",
            "Successfully built xml_cleaner\n",
            "Installing collected packages: xml_cleaner\n",
            "Successfully installed xml_cleaner-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = []\n",
        "for file in list_of_files:\n",
        "  if file.endswith('.epub'):\n",
        "    batch.append(file)"
      ],
      "metadata": {
        "id": "0fgxqKdwuhP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from epub_conversion.utils import open_book, convert_epub_to_lines, convert_lines_to_text\n",
        "title = []\n",
        "content = []\n",
        "for file in batch:\n",
        "  file_path = os.path.join(directory_path, file)\n",
        "  book = open_book(file_path)\n",
        "  lines = convert_epub_to_lines(book)\n",
        "  text = convert_lines_to_text(text_content)\n",
        "  for i in text:\n",
        "    content.append(i)\n",
        "    title.append(file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO-aPX7zu4nr",
        "outputId": "8ebf69f3-7956-4024-a30e-700421606296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/epub/__init__.py:139: SyntaxWarning: The ePub does not define any NCX file\n",
            "  warnings.warn('The ePub does not define any NCX file',\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'file': title, 'text': content})\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lAxZkEFwEls",
        "outputId": "1000e9bd-a941-4029-a41f-baf58c18e42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     file  \\\n",
            "0       What is Microhistory_ Theory and practice -- S...   \n",
            "1       What is Microhistory_ Theory and practice -- S...   \n",
            "2       What is Microhistory_ Theory and practice -- S...   \n",
            "3       What is Microhistory_ Theory and practice -- S...   \n",
            "4       What is Microhistory_ Theory and practice -- S...   \n",
            "...                                                   ...   \n",
            "106262  Occupational Socialization and Working Lives (...   \n",
            "106263  Occupational Socialization and Working Lives (...   \n",
            "106264  Occupational Socialization and Working Lives (...   \n",
            "106265  Occupational Socialization and Working Lives (...   \n",
            "106266  Occupational Socialization and Working Lives (...   \n",
            "\n",
            "                                                     text  \n",
            "0        Routledge Revivals Occupational Socialization...  \n",
            "1       The series publishes original sociological res...  \n",
            "2       The series includes monographs reporting on em...  \n",
            "3       Occupational Socialization and Occupational So...  \n",
            "4       He has extensive research and publishing exper...  \n",
            "...                                                   ...  \n",
            "106262                   London : Collier - Macmillan .\\n  \n",
            "106263        Microcomputing and Qualitative Analysis .\\n  \n",
            "106264                            Aldershot : Avebury .\\n  \n",
            "106265                               Scientific Elite .\\n  \n",
            "106266                          New York : Free Press .\\n  \n",
            "\n",
            "[106267 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(out_dir + '/'+ 'epub.csv')"
      ],
      "metadata": {
        "id": "obU0VXhv0B-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/df/epub.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/df/all_texts.csv')\n",
        "\n",
        "df3 = pd.concat([df, df2], ignore_index=True)\n",
        "df3.to_csv('/content/drive/MyDrive/df/all_texts.csv')"
      ],
      "metadata": {
        "id": "t0Bdlh3eExrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}